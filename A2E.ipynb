{"cells":[{"cell_type":"markdown","source":["Use EGG Fourier descriptors\n","Use the whole EGG segments\n","\n","Padded\n","One layer LSTM: no\n","Try MFCCs\n","\n","Use EGG Fourier descriptors\n","Use the whole EGG segments\n","\n","Padded\n","One layer LSTM: no\n","Try MFCCs\n","\n","Add Window: several inputs predict one output wave form\n","\n","Reinforce learning: Since the input is not segmented\n","\n","Giving a fixed length of audio and EGG, choose the representative EGG\n","\n","不管什么cycles了，直接简单粗暴对应，但是采样低一点？或者EGG可以粗糙一些？或者EGG整体用一个什么东西来表示，或者还是descriptor，但是没有值的时候用零值。"],"metadata":{"id":"7xZzOKiUmLK_"}},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19313,"status":"ok","timestamp":1676626158932,"user":{"displayName":"Huanchen Cai","userId":"09647300903139575150"},"user_tz":-60},"id":"d9c_cqZo0uN-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"49516c15-73a0-491a-88ca-67eb2fa18c0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Num GPUs Available:  1\n"]}],"source":["# From Voice_EGG.wav and Log.aiff generate input and output items.\n","# Voice_EGG.wav format:\n","#   Channel 1: Mic signal; Channel 2: EGG signal.\n","# Log.aiff format:\n","import wave\n","import os\n","import numpy as np\n","import librosa\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from scipy.io import wavfile\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Masking, LSTM, Dense, RepeatVector, TimeDistributed\n","\n","#drive = r'F:\\A2E\\test file'\n","drive = '/content/drive/MyDrive/Colab Notebooks/Test File'\n","\n","MicFile = ''\n","CycleFile = 'test_CycleDetection.wav'\n","FFTDFile = 'test_Log.csv'\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9jwFciqYPPbE","executionInfo":{"status":"ok","timestamp":1675964699732,"user_tz":-60,"elapsed":418,"user":{"displayName":"Huanchen Cai","userId":"09647300903139575150"}},"outputId":"fea00cdc-6106-4a89-b63f-9cf696977989"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Feb  9 17:44:57 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P8    12W /  70W |      3MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["def load_cycle_dataset(folder):\n","    # Use Cycle file for training\n","    #\n","    mic_cycle_suffix = 'test_CycleDetection.wav'\n","    EGG_suffix = 'test_Log.csv'\n","    # save Cycle file into two arrays, var cycle contains breakpoints in detecting EGG waveforms\n","    samplerate, mic_cycle = wavfile.read(os.path.join(drive, 'test_CycleDetection.wav'))\n","    mic = mic_cycle[:, 0]\n","    cycle = mic_cycle[:, 1]\n","    # save log file's first column (time stamp) as np arrays\n","    with open(os.path.join(folder, EGG_suffix)) as E:\n","        EGG = np.loadtxt(E, delimiter=',')\n","        EGG =\n","    return mic, cycle, EGG\n","class CycleDataset:\n","    def __init__(self):\n","        self.problem_type = 'en-spa'\n","        self.inp_lang_tokenizer = None\n","        self.targ_lang_tokenizer = None\n","\n","    def preprocess(self, audio):\n","        return audio_processed"],"metadata":{"id":"I4E0pLyyp-Vu","colab":{"base_uri":"https://localhost:8080/","height":137},"executionInfo":{"status":"error","timestamp":1675801748359,"user_tz":-60,"elapsed":3,"user":{"displayName":"Huanchen Cai","userId":"09647300903139575150"}},"outputId":"f538581d-45b1-4576-f406-9ebf9f26d384"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0aa733d98d44>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    EGG =\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["# Log file including timing and FFT descriptors\n","FFTData = os.path.join(drive, FFTDFile)\n","FFT = np.loadtxt(FFTData, delimiter=',')\n","sliced = []\n","for i in range(len(FFT)):\n","    dit = FFT[i, 0] * 44100\n","    sliced.append(round(dit))\n","print(len(sliced))\n","\n","# Mic data sliced into sequences, --> Input\n","Samplerate, Mic = wavfile.read(os.path.join(drive, CycleFile))\n","MicData = Mic[:, 0]\n","slicedData = []\n","for i in range(len(sliced)-1):\n","    temp = MicData[sliced[i]:sliced[i+1]]\n","    slicedData.append(temp)\n","max_len = len(slicedData)\n","max_dim = max([len(d) for d in slicedData])\n","padded_data = np.zeros((len(slicedData), max_dim))\n","for i,d in enumerate(slicedData):\n","  padded_data[i,:len(d)] = d\n","#slicedData = np.array(slicedData, dtype=object)\n","#slicedData = np.pad(slicedData,100, 'constant')\n","\n","# Fourier Arrays --> output\n","FourierArray = np.array(FFT[:-1, 12:])\n","\n","# Validation group, used to calculate the distance trained vs. collected\n","MetricData = FFT[:, [1, 2, 3, 4, 5, 6, 8, 9, 10, 11]]"],"metadata":{"id":"7uXW9jkn01e2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"256555d7-9c4b-4be9-dc9f-d99beec95cf4","executionInfo":{"status":"ok","timestamp":1676626174108,"user_tz":-60,"elapsed":4866,"user":{"displayName":"Huanchen Cai","userId":"09647300903139575150"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["12425\n"]}]},{"cell_type":"markdown","metadata":{"id":"SISTDdH9KRki"},"source":["Pre-Processing"]},{"cell_type":"markdown","source":["To be functioned"],"metadata":{"id":"n3x_4_vEnCTG"}},{"cell_type":"code","source":["audio, sr = librosa.load(os.path.join(drive, CycleFile), sr=44100)\n","# Define the frame size and hop length\n","frame_size = 1024\n","hop_length = 512\n","\n","# Compute the MFCC features\n","mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=20, n_fft=frame_size, hop_length=hop_length)\n","\n","# Compute the frame duration and average frame rate\n","frame_duration = frame_size / sr\n","frame_rate = 1 / (frame_duration * hop_length / sr)"],"metadata":{"id":"-Ub3aAwemwc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eF4rD6p9rokf"},"outputs":[],"source":["scaler = MinMaxScaler()\n","\n","# Fit and transform the data\n","scaled_FourierArray = scaler.fit_transform(FourierArray)\n","scaled_padded_data = scaler.fit_transform(padded_data)\n","# Split data into training and test sets (70% for training and 30% for test)\n","X_train, X_test, y_train, y_test = train_test_split(scaled_padded_data, scaled_FourierArray, test_size=0.3)\n","\n","# Split the training data into training and validation sets (70% for training and 30% for validation)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3)\n","\n"]},{"cell_type":"code","source":["# Concatenate the input and output data\n","training_set = np.concatenate((X_train, y_train), axis=1)\n","\n","# Randomly permute the indices of the training data\n","permuted_indices = np.random.permutation(training_set.shape[0])\n","permuted_training_data = training_set[permuted_indices]\n","\n","# Split the permuted data back into the input and output arrays\n","X_train, y_train = np.split(permuted_training_data, [X_train.shape[1]], axis=1)\n","\n","X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n","X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n","X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], 1))\n","#y_train = np.reshape(y_train, (batch_size, y_train.shape[0], y_train.shape[1]))\n","#y_val = np.reshape(y_val, (batch_size, y_val.shape[0], y_val.shape[1]))\n","\n"],"metadata":{"id":"fWjqlIHaAxdk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d6Fxro60L0oo"},"source":["Training session"]},{"cell_type":"code","source":["inputs = tf.keras.layers.Input(shape=(X_train.shape[1], 1))\n","\n","# LSTM layer\n","lstm = tf.keras.layers.LSTM(1024)(inputs)\n","\n","\n","\n","\n","# Output layer\n","outputs = tf.keras.layers.Dense(22, activation='softmax')(lstm)\n","\n","# Model\n","model = tf.keras.models.Model(inputs, outputs)\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","\n","# Fit the model on the input data\n","model.fit(X_train[:1000, :, :], y_train[:1000, :], epochs=10, batch_size=8, validation_data=(X_val, y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p2BBRmaNdQli","outputId":"d3c99060-aad1-417f-d89d-92e3935b15fc","executionInfo":{"status":"ok","timestamp":1676641436358,"user_tz":-60,"elapsed":14207135,"user":{"displayName":"Huanchen Cai","userId":"09647300903139575150"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","125/125 [==============================] - 1430s 11s/step - loss: 0.3130 - accuracy: 0.1170 - val_loss: 0.3105 - val_accuracy: 0.0456\n","Epoch 2/10\n","125/125 [==============================] - 1428s 11s/step - loss: 0.3122 - accuracy: 0.1270 - val_loss: 0.3105 - val_accuracy: 0.2675\n","Epoch 3/10\n","125/125 [==============================] - 1427s 11s/step - loss: 0.3122 - accuracy: 0.1800 - val_loss: 0.3104 - val_accuracy: 0.1821\n","Epoch 4/10\n","125/125 [==============================] - 1427s 11s/step - loss: 0.3122 - accuracy: 0.1560 - val_loss: 0.3104 - val_accuracy: 0.1821\n","Epoch 5/10\n","125/125 [==============================] - 1427s 11s/step - loss: 0.3121 - accuracy: 0.1610 - val_loss: 0.3104 - val_accuracy: 0.1012\n","Epoch 6/10\n","125/125 [==============================] - 1376s 11s/step - loss: 0.3121 - accuracy: 0.1380 - val_loss: 0.3104 - val_accuracy: 0.0517\n","Epoch 7/10\n","125/125 [==============================] - 1427s 11s/step - loss: 0.3122 - accuracy: 0.1560 - val_loss: 0.3104 - val_accuracy: 0.0399\n","Epoch 8/10\n","125/125 [==============================] - 1427s 11s/step - loss: 0.3121 - accuracy: 0.1590 - val_loss: 0.3104 - val_accuracy: 0.1012\n","Epoch 9/10\n","125/125 [==============================] - 1434s 12s/step - loss: 0.3121 - accuracy: 0.1500 - val_loss: 0.3104 - val_accuracy: 0.1821\n","Epoch 10/10\n","125/125 [==============================] - 1401s 11s/step - loss: 0.3121 - accuracy: 0.1720 - val_loss: 0.3104 - val_accuracy: 0.0456\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa702f4fd0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDkmTray0x5r"},"outputs":[],"source":["model = Sequential([\n","    LSTM(128, input_shape=(X_train.shape[1], 1)),\n","    Dense(22, activation='softmax')\n","])\n","model.summary()\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=64, verbose=2)\n"]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.lstm = nn.LSTM(input_size, hidden_size)\n","\n","    def forward(self, input, hidden, cell):\n","        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n","        return output, hidden, cell\n","\n","    def init_hidden_cell(self, batch_size):\n","        hidden = torch.zeros(1, batch_size, self.hidden_size)\n","        cell = torch.zeros(1, batch_size, self.hidden_size)\n","        return hidden, cell\n","\n","class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.lstm = nn.LSTM(hidden_size, output_size)\n","\n","    def forward(self, input, hidden, cell):\n","        output, (hidden, cell) = self.lstm(input, (hidden, cell))\n","        return output, hidden, cell\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, source, target, teacher_forcing_ratio = 0.5):\n","        batch_size = source.size(1)\n","        target_len = target.size(0)\n","        target_vocab_size = self.decoder.lstm.out_features\n","\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n","\n","        hidden, cell = self.encoder.init_hidden_cell(batch_size)\n","        encoder_output, hidden, cell = self.encoder(source, hidden, cell)\n","\n","        decoder_input = torch.zeros(1, batch_size, target_vocab_size)\n","\n","        for t in range(target_len):\n","            decoder_output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n","            outputs[t] = decoder_output\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            decoder_input = target[t] if teacher_force else decoder_output.argmax(1).unsqueeze(0)\n","\n","        return outputs"],"metadata":{"id":"Ek-gBtUZZmZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder()\n","model = Seq2Seq()\n","model.forward(X_train, y_train)"],"metadata":{"id":"fz0okHu2blEl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4fc0WMVqs2-h"},"source":["Test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpDzf4cKs2Qa"},"outputs":[],"source":["# Evaluate the model on test data\n","score = model.evaluate(X_test, y_test, verbose=2)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPvapoqXIG/HweMyfhWw6aP"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}